[üè† ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å](../../README.md) | [üìö ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç](README.md)

---

# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 4: ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ö‡∏ó‡∏ô‡∏µ‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô `examples/` ‡∏Ç‡∏≠‡∏á repo ‡∏à‡∏£‡∏¥‡∏á

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1: ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏à‡∏î‡∏à‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤

**‡πÑ‡∏ü‡∏•‡πå**: [`examples/example_1_conversation_memory.py`](../../examples/example_1_conversation_memory.py)

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á memory categories ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞:

1. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ 3 ‡πÑ‡∏ü‡∏•‡πå
2. ‡∏™‡∏Å‡∏±‡∏î memory items ‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
3. ‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö items ‡πÄ‡∏õ‡πá‡∏ô categories
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Markdown ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ category

### ‡πÇ‡∏Ñ‡πâ‡∏î

```python
import asyncio
import os
from memu.app import MemoryService


async def main():
    print("Example 1: Conversation Memory Processing")
    print("-" * 50)

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("Please set OPENAI_API_KEY environment variable")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á service ‡∏î‡πâ‡∏ß‡∏¢ OpenAI
    service = MemoryService(
        llm_profiles={
            "default": {
                "api_key": api_key,
                "chat_model": "gpt-4o-mini",
            },
        },
    )

    # ‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    conversation_files = [
        "examples/resources/conversations/conv1.json",
        "examples/resources/conversations/conv2.json",
        "examples/resources/conversations/conv3.json",
    ]

    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
    total_items = 0
    categories = []

    for conv_file in conversation_files:
        if not os.path.exists(conv_file):
            continue

        result = await service.memorize(
            resource_url=conv_file,
            modality="conversation"
        )
        total_items += len(result.get("items", []))
        # categories ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å memorize ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        categories = result.get("categories", [])

    print(f"‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(conversation_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"‚úì ‡∏™‡∏Å‡∏±‡∏î {total_items} memory items")
    print(f"‚úì ‡∏™‡∏£‡πâ‡∏≤‡∏á {len(categories)} categories")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• categories
    for cat in categories:
        print(f"\nüìÅ {cat['name']}")
        summary = cat.get('summary', '')[:100]
        print(f"   {summary}...")


asyncio.run(main())
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
```

### ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

```
Example 1: Conversation Memory Processing
--------------------------------------------------
‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 3 ‡πÑ‡∏ü‡∏•‡πå
‚úì ‡∏™‡∏Å‡∏±‡∏î 15 memory items
‚úì ‡∏™‡∏£‡πâ‡∏≤‡∏á 4 categories

üìÅ preferences
   ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏≠‡∏ö dark mode ‡πÅ‡∏•‡∏∞ minimal UI ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ notifications...

üìÅ technical_skills
   ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç Python, JavaScript ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô React...

üìÅ work_context
   ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô startup ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á senior developer ‡∏ó‡∏µ‡∏° 5 ‡∏Ñ‡∏ô...

üìÅ communication_style
   ‡∏ä‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÉ‡∏ä‡πâ bullet points...
```

Output files ‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà `examples/output/conversation_example/`

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2: Agent ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á

**‡πÑ‡∏ü‡∏•‡πå**: [`examples/example_2_skill_extraction.py`](../../examples/example_2_skill_extraction.py)

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á **Incremental Learning** ‚Äî ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:

1. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• deployment logs ‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
2. ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï** ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà)
3. Category summaries ‡∏ß‡∏¥‡∏ß‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏° knowledge ‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏™‡∏°
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á `skill.md` ‚Äî ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠ deployment ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á

### Custom Memory Types ‡πÅ‡∏•‡∏∞ Categories

```python
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î prompt ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö skill extraction
skill_prompt = """
You are analyzing an agent execution log. Extract:

1. **Action/Phase**: What was being attempted?
2. **Status**: SUCCESS ‚úÖ or FAILURE ‚ùå
3. **What Happened**: What was executed
4. **Outcome**: What worked/failed, metrics
5. **Root Cause** (for failures): Why did it fail?
6. **Lesson**: What did we learn?

Text: {resource}
"""

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î categories ‡πÄ‡∏≠‡∏á
skill_categories = [
    {"name": "deployment_execution", "description": "Deployment actions"},
    {"name": "incident_response_rollback", "description": "Error handling"},
    {"name": "performance_monitoring", "description": "Metrics analysis"},
    {"name": "lessons_learned", "description": "Key insights"},
]

memorize_config = {
    "memory_types": ["skill"],
    "memory_type_prompts": {"skill": skill_prompt},
    "memory_categories": skill_categories,
}

service = MemoryService(
    llm_profiles={"default": {"api_key": api_key, "chat_model": "gpt-4o-mini"}},
    memorize_config=memorize_config,
)
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
```

### ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á

```
Example 2: Incremental Skill Extraction
--------------------------------------------------
Processing files...

‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• 3 ‡πÑ‡∏ü‡∏•‡πå
‚úì ‡∏™‡∏Å‡∏±‡∏î 12 skills
‚úì Output: examples/output/skill_example/
```

‡πÑ‡∏ü‡∏•‡πå output:
- `examples/output/skill_example/log_1.md` ‚Äî ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• log ‡πÅ‡∏£‡∏Å
- `examples/output/skill_example/log_2.md` ‚Äî ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• log ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á
- `examples/output/skill_example/log_3.md` ‚Äî ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• log ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°
- `examples/output/skill_example/skill.md` ‚Äî **‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢** ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å logs

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3: ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (Multimodal)

**‡πÑ‡∏ü‡∏•‡πå**: [`examples/example_3_multimodal_memory.py`](../../examples/example_3_multimodal_memory.py)

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢ modalities (‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ + ‡∏†‡∏≤‡∏û) ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á unified memory categories:

1. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• text documents 2 ‡πÑ‡∏ü‡∏•‡πå
2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• image 1 ‡πÑ‡∏ü‡∏•‡πå
3. ‡∏£‡∏ß‡∏° knowledge ‡∏Ç‡πâ‡∏≤‡∏° modalities

### ‡πÇ‡∏Ñ‡πâ‡∏î

```python
import asyncio
import os
from memu.app import MemoryService


async def main():
    api_key = os.getenv("OPENAI_API_KEY")

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î categories ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö multimodal content
    multimodal_categories = [
        {"name": "technical_documentation", "description": "Technical guides"},
        {"name": "architecture_concepts", "description": "System architecture"},
        {"name": "best_practices", "description": "Best practices"},
        {"name": "code_examples", "description": "Code snippets"},
        {"name": "visual_diagrams", "description": "Visual concepts from images"},
    ]

    service = MemoryService(
        llm_profiles={
            "default": {
                "api_key": api_key,
                "chat_model": "gpt-4o-mini",  # ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö vision
            }
        },
        memorize_config={"memory_categories": multimodal_categories},
    )

    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏•‡∏≤‡∏¢ modalities
    resources = [
        ("examples/resources/docs/doc1.txt", "document"),
        ("examples/resources/docs/doc2.txt", "document"),
        ("examples/resources/images/image1.png", "image"),  # ‚Üê ‡∏†‡∏≤‡∏û!
    ]

    total_items = 0
    categories = []

    for resource_file, modality in resources:
        if not os.path.exists(resource_file):
            continue

        result = await service.memorize(
            resource_url=resource_file,
            modality=modality,
        )
        total_items += len(result.get("items", []))
        categories = result.get("categories", [])

    print(f"‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(resources)} resources ({2} documents + 1 image)")
    print(f"‚úì ‡∏™‡∏Å‡∏±‡∏î {total_items} items ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å modalities")
    print(f"‚úì ‡∏£‡∏ß‡∏° {len(categories)} unified categories")


asyncio.run(main())
```

### ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

- ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö **vision** (‡πÄ‡∏ä‡πà‡∏ô `gpt-4o-mini`, `gpt-4o`)
- ‡∏†‡∏≤‡∏û‡∏à‡∏∞‡∏ñ‡∏π‡∏Å analyze ‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô text descriptions
- memory items ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô category ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
export OPENAI_API_KEY=your_api_key
python examples/example_3_multimodal_memory.py
```

---

## ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 4: OpenRouter Integration

**‡πÑ‡∏ü‡∏•‡πå**: [`examples/example_4_openrouter_memory.py`](../../examples/example_4_openrouter_memory.py)

### ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ [OpenRouter](https://openrouter.ai) ‡πÅ‡∏ó‡∏ô OpenAI ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á OpenRouter:

- ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á LLM ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ú‡πà‡∏≤‡∏ô API ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
- ‡πÉ‡∏ä‡πâ Claude, Gemini, Llama, ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô‡πÜ
- API ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö OpenAI

### ‡πÇ‡∏Ñ‡πâ‡∏î

```python
import asyncio
import os
from memu.app import MemoryService


async def main():
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        raise ValueError("Please set OPENROUTER_API_KEY environment variable")

    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OpenRouter
    service = MemoryService(
        llm_profiles={
            "default": {
                "provider": "openrouter",
                "client_backend": "httpx",
                "base_url": "https://openrouter.ai",
                "api_key": api_key,
                # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                "chat_model": "anthropic/claude-3.5-sonnet",
                "embed_model": "openai/text-embedding-3-small",
            },
        },
    )

    conversation_files = [
        "examples/resources/conversations/conv1.json",
        "examples/resources/conversations/conv2.json",
        "examples/resources/conversations/conv3.json",
    ]

    total_items = 0
    categories = []

    for conv_file in conversation_files:
        if not os.path.exists(conv_file):
            print(f"‡∏Ç‡πâ‡∏≤‡∏°: {conv_file} ‡πÑ‡∏°‡πà‡∏û‡∏ö")
            continue

        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {conv_file}")
        result = await service.memorize(
            resource_url=conv_file,
            modality="conversation"
        )
        total_items += len(result.get("items", []))
        categories = result.get("categories", [])

    print(f"\n‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(conversation_files)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"‡∏™‡∏Å‡∏±‡∏î {total_items} items")
    print(f"‡∏™‡∏£‡πâ‡∏≤‡∏á {len(categories)} categories")


asyncio.run(main())
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏±‡∏ô

```bash
export OPENROUTER_API_KEY=your_api_key
python examples/example_4_openrouter_memory.py
```

### ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ö‡∏ô OpenRouter

| ‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô OpenRouter | ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ |
|------|-----------------|---------|
| Claude 3.5 Sonnet | `anthropic/claude-3.5-sonnet` | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô complex |
| GPT-4o | `openai/gpt-4o` | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö vision |
| Llama 3.1 | `meta-llama/llama-3.1-70b-instruct` | open source |
| Gemini Pro | `google/gemini-pro` | Google's model |

---

## ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á

| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á | Use Case | Modality | Custom Config |
|---------|---------|---------|--------------|
| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 1 | Personal assistant | conversation | ‚ùå |
| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 2 | DevOps automation | document (logs) | ‚úÖ custom types + categories |
| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 | Research assistant | document + image | ‚úÖ custom categories |
| ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 4 | Any + OpenRouter | conversation | ‚úÖ custom provider |

---

## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

- üìñ [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 5: PostgreSQL](05-‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á-PostgreSQL.md) ‚Äî ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ production database
- üìñ [‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6: ‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏≤‡∏ô‡∏£‡∏ß‡∏°](06-‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏≤‡∏ô‡∏£‡∏ß‡∏°.md) ‚Äî ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö LangGraph
