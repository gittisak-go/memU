[üè† ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å](../../README.md) | [üìö ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç](README.md)

---

# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6: ‡∏Å‡∏≤‡∏£‡∏ú‡∏™‡∏≤‡∏ô‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö Framework ‡∏≠‡∏∑‡πà‡∏ô

---

## LangGraph Integration

[LangGraph](https://langchain-ai.github.io/langgraph/) ‡∏Ñ‡∏∑‡∏≠ framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á stateful AI agents memU ‡∏°‡∏µ integration ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ú‡πà‡∏≤‡∏ô `MemULangGraphTools`

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
pip install langgraph langchain-core langchain-openai

# ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢ uv
uv add langgraph langchain-core langchain-openai

# ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≤‡∏Å source
pip install -e ".[langgraph]"
```

### ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° memU ‡πÄ‡∏õ‡πá‡∏ô Memory Node

```python
import asyncio
import os
from memu.app.service import MemoryService
from memu.integrations.langgraph import MemULangGraphTools


async def main():
    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á MemoryService
    memory_service = MemoryService(
        llm_profiles={
            "default": {
                "api_key": os.getenv("OPENAI_API_KEY"),
                "chat_model": "gpt-4o-mini",
            }
        },
        database_config={
            "metadata_store": {"provider": "inmemory"},
        },
    )

    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á MemULangGraphTools
    memu_tools = MemULangGraphTools(memory_service)

    # ‡∏î‡∏∂‡∏á tools list (BaseTool compatible)
    tools = memu_tools.tools()
    print(f"Available tools: {[t.name for t in tools]}")
    # Output: ['save_memory', 'search_memory']

    # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å memory
    save_tool = memu_tools.save_memory_tool()
    result = await save_tool.ainvoke({
        "content": "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏≠‡∏ö dark mode ‡πÅ‡∏•‡∏∞ minimal interface",
        "user_id": "user_123",
        "metadata": {"category": "preferences"}
    })
    print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {result}")

    # 4. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ memory
    search_tool = memu_tools.search_memory_tool()
    search_result = await search_tool.ainvoke({
        "query": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?",
        "user_id": "user_123",
        "limit": 5,
    })
    print(f"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:\n{search_result}")


asyncio.run(main())
```

### ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö LangGraph StateGraph

```python
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from typing import TypedDict, Annotated
import operator


class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    user_id: str


# ‡∏™‡∏£‡πâ‡∏≤‡∏á tools ‡∏à‡∏≤‡∏Å memU
memu_tools = MemULangGraphTools(memory_service)
tools = memu_tools.tools()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° tools
llm = ChatOpenAI(model="gpt-4o-mini").bind_tools(tools)


def agent_node(state: AgentState):
    """Agent node ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ memU tools"""
    messages = state["messages"]
    response = llm.invoke(messages)
    return {"messages": [response]}


def should_continue(state: AgentState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "tools"
    return END


# ‡∏™‡∏£‡πâ‡∏≤‡∏á graph
workflow = StateGraph(AgentState)
workflow.add_node("agent", agent_node)
workflow.add_node("tools", ToolNode(tools))
workflow.set_entry_point("agent")
workflow.add_conditional_edges("agent", should_continue)
workflow.add_edge("tools", "agent")

app = workflow.compile()

# ‡∏£‡∏±‡∏ô agent
result = app.invoke({
    "messages": [{"role": "user", "content": "‡∏à‡∏≥‡πÑ‡∏ß‡πâ‡∏ß‡πà‡∏≤‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö Python"}],
    "user_id": "user_123",
})
```

### API Reference ‡∏Ç‡∏≠‡∏á MemULangGraphTools

#### `save_memory_tool()`

‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ

| Parameter | Type | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|-----------|------|---------|
| `content` | `str` | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å |
| `user_id` | `str` | ID ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ |
| `metadata` | `dict` | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (Optional) |

#### `search_memory_tool()`

‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

| Parameter | Type | Default | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|-----------|------|---------|---------|
| `query` | `str` | ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô | ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ |
| `user_id` | `str` | ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô | ID ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ |
| `limit` | `int` | 5 | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå |
| `metadata_filter` | `dict` | None | ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° metadata |
| `min_relevance_score` | `float` | 0.0 | ‡∏Ñ‡πà‡∏≤ relevance ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ |

---

## OpenRouter Integration

[OpenRouter](https://openrouter.ai) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á LLM ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ú‡πà‡∏≤‡∏ô API ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ API keys ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

```bash
export OPENROUTER_API_KEY=your-key-from-openrouter-ai
```

```python
from memu.app import MemoryService

service = MemoryService(
    llm_profiles={
        "default": {
            "provider": "openrouter",
            "client_backend": "httpx",
            "base_url": "https://openrouter.ai",
            "api_key": "your-openrouter-api-key",
            "chat_model": "anthropic/claude-3.5-sonnet",
            "embed_model": "openai/text-embedding-3-small",
        },
    },
)
```

### ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

| ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó | ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ |
|-------|-------------|---------|
| Chat | `anthropic/claude-3.5-sonnet` | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô complex |
| Chat | `openai/gpt-4o` | ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö vision |
| Chat | `meta-llama/llama-3.1-70b-instruct` | open source |
| Embedding | `openai/text-embedding-3-small` | ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î |
| Embedding | `openai/text-embedding-3-large` | ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏ß‡πà‡∏≤ |

### ‡∏£‡∏±‡∏ô tests

```bash
export OPENROUTER_API_KEY=your_api_key

# Full workflow test
python tests/test_openrouter.py

# Embedding-specific tests
python tests/test_openrouter_embedding.py

# Vision tests
python tests/test_openrouter_vision.py
```

---

## Custom LLM Providers

### Qwen (Alibaba Cloud)

```python
service = MemoryService(
    llm_profiles={
        "default": {
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": os.getenv("DASHSCOPE_API_KEY"),
            "chat_model": "qwen3-max",
            "client_backend": "sdk",
        },
        # Voyage AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö embeddings (Optional)
        "embedding": {
            "base_url": "https://api.voyageai.com/v1",
            "api_key": os.getenv("VOYAGE_API_KEY"),
            "embed_model": "voyage-3.5-lite",
        },
    },
)
```

### Grok (xAI)

```python
from memu.app.settings import LLMConfig

# ‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô settings
config = LLMConfig(
    provider="grok",
    # ‡πÉ‡∏ä‡πâ XAI_API_KEY environment variable ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    # chat_model ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: grok-2-latest
    # base_url ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: https://api.x.ai/v1
)
```

```bash
export XAI_API_KEY=your-xai-api-key

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ú‡πà‡∏≤‡∏ô llm_profiles
service = MemoryService(
    llm_profiles={
        "default": {
            "base_url": "https://api.x.ai/v1",
            "api_key": os.getenv("XAI_API_KEY"),
            "chat_model": "grok-2-latest",
        }
    }
)
```

### Claude (Anthropic) ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

```python
service = MemoryService(
    llm_profiles={
        "default": {
            "base_url": "https://api.anthropic.com/v1",
            "api_key": os.getenv("ANTHROPIC_API_KEY"),
            "chat_model": "claude-3-5-sonnet-20241022",
            "client_backend": "http",
        },
    },
)
```

---

## MCP (Model Context Protocol)

memU ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö MCP servers ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI applications ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö repo ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö MCP integration ‡∏ó‡∏µ‡πà [GitHub Issues](https://github.com/NevaMind-AI/memU/issues)

---

## LazyLLM Integration

memU ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö [LazyLLM](https://github.com/LazyAGI/LazyLLM) framework:

```bash
pip install lazyllm
```

```python
# ‡∏î‡∏π examples/example_5_with_lazyllm_client.py ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ï‡πá‡∏°
```

---

## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

- üè† [‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å](../../README.md)
- üìö [README ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](../../readme/README_th.md)
- üí¨ [Discord Community](https://discord.com/invite/hQZntfGsbJ) ‚Äî ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ä‡∏£‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå
